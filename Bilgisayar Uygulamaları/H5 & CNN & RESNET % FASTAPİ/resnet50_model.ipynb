{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5976b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def collect_image_paths(root_dir):\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "    return sorted(p for p in Path(root_dir).rglob(\"*\") if p.suffix.lower() in exts)\n",
    "\n",
    "def build_label_df(paths):\n",
    "    records = []\n",
    "    cat_set = {\n",
    "        \"Abyssinian\",\"Birman\",\"Bengal\",\"Bombay\",\"British\",\n",
    "        \"Egyptian\",\"Maine\",\"Persian\",\"american\",\"english\"\n",
    "    }\n",
    "    for p in paths:\n",
    "        label_str = p.stem.split(\"_\")[0]\n",
    "        binary = 0 if label_str in cat_set else 1\n",
    "        records.append({\"path\": str(p), \"label\": binary})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "def df_to_dataset(df, shuffle=True):\n",
    "    paths = df[\"path\"].values\n",
    "    labels = df[\"label\"].values\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(df))\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "def _load_and_preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = preprocess_input(img)\n",
    "    return img, tf.cast(label, tf.int32)\n",
    "\n",
    "\n",
    "def build_resnet50_feature_extractor():\n",
    "    base = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                    input_shape=(*IMG_SIZE,3))\n",
    "    base.trainable = False\n",
    "    inputs = layers.Input((*IMG_SIZE,3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"resnet50_feature\")\n",
    "\n",
    "def build_resnet50_fine_tuner(fine_tune_at=140):\n",
    "    base = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                    input_shape=(*IMG_SIZE,3))\n",
    "    base.trainable = False\n",
    "    for layer in base.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n",
    "    inputs = layers.Input((*IMG_SIZE,3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return models.Model(inputs, outputs, name=\"resnet50_finetune\")\n",
    "\n",
    "\n",
    "def compile_and_train(model, train_ds, val_ds, output_path,\n",
    "                      epochs=10, lr=1e-4):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        output_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Bilgisayar Proglamlama\\images\"\n",
    "    paths = collect_image_paths(root_folder)\n",
    "    df = build_label_df(paths)\n",
    "    train_df, val_df = train_test_split(\n",
    "        df, test_size=0.2,\n",
    "        stratify=df[\"label\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    train_ds = df_to_dataset(train_df, shuffle=True)\n",
    "    val_ds   = df_to_dataset(val_df, shuffle=False)\n",
    "\n",
    "    # 4.1 Feature Extraction\n",
    "    feat_model = build_resnet50_feature_extractor()\n",
    "    hist_feat = compile_and_train(\n",
    "        feat_model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        output_path=\"best_resnet50_feature.h5\",\n",
    "        epochs=5,\n",
    "        lr=1e-4\n",
    "    )\n",
    "\n",
    "    feat_model.save(\"best_resnet50_feature.h5\")\n",
    "\n",
    "    # 4.2 Fine-Tuning\n",
    "    ft_model = build_resnet50_fine_tuner(fine_tune_at=140)\n",
    "    hist_ft = compile_and_train(\n",
    "        ft_model,\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        output_path=\"best_resnet50_finetune.h5\",\n",
    "        epochs=5,\n",
    "        lr=1e-5\n",
    "    )\n",
    "    ft_model.save(\"best_resnet50_finetune.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
